{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import tqdm\n",
    "import datetime\n",
    "from language_detection.data import DataLoader, load_wili_2018_dataset, batch_collate_function, get_mask_from_lengths\n",
    "from language_detection.model import TrainingConfig, TransformerClassifier, create_datasets, evaluate_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = \"./experiments/wili2018/wili2018-checkpoint-000020.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pathlib.Path(checkpoint_filepath).is_file():\n",
    "    raise ValueError(f\"checkpoint file '{checkpoint_filepath}' does not exist!\")\n",
    "checkpoint = torch.load(checkpoint_filepath)\n",
    "config = TrainingConfig(**checkpoint[\"config\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "loading model with num_classes 235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"\\nloading model from checkpoint '{checkpoint}'\")\n",
    "model = TransformerClassifier(num_classes=checkpoint[\"num_classes\"])\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA detected, using gpu\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA detected, using gpu\")\n",
    "    device_string = \"cuda\"\n",
    "else:\n",
    "    print(f\"warning! no CUDA detected, using cpu\")\n",
    "    device_string = \"cpu\"\n",
    "_ = model.to(device_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-28 15:40:22.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlanguage_detection.data.loaders\u001b[0m:\u001b[36mload_wili_2018_dataset\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1m'drop_duplicates' is true, dropping duplicates from *training* set...\u001b[0m\n",
      "\u001b[32m2023-11-28 15:40:22.985\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlanguage_detection.data.loaders\u001b[0m:\u001b[36mload_wili_2018_dataset\u001b[0m:\u001b[36m74\u001b[0m - \u001b[1mdropped 3117 samples from training data that also appeared in the test data\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "raw_data = load_wili_2018_dataset(config.data_path)\n",
    "if config.debug:\n",
    "    print(f\"debug mode is true, so truncate test to few elements only\")\n",
    "    raw_data.x_test = raw_data.x_test[:1024]\n",
    "    raw_data.y_test = raw_data.y_test[:1024]\n",
    "\n",
    "_, _, test_dataset = create_datasets(\n",
    "    raw_data, max_seq_len=config.max_length, dev_pct=config.dev_pct\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_dataset, batch_size=config.batch_size, shuffle=False, num_workers=0, collate_fn=batch_collate_function\n",
    ")\n",
    "num_classes = len(raw_data.idx2lang)\n",
    "if checkpoint[\"num_classes\"] != num_classes:\n",
    "    raise ValueError(f\"model's {checkpoint['num_classes']} output classes != data's {num_classes} classes, is this the correct dataset?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-28T15:21:55.600032] starting evaluation on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3672/3672 [09:47<00:00,  6.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-11-28T15:31:42.915205] test clf loss : 10.93545\n",
      "[2023-11-28T15:31:43.672673] test micro prc: 0.90686,\tmacro 0.91144\n",
      "[2023-11-28T15:31:43.672738] test micro rcl: 0.90686,\tmacro 0.90686\n",
      "[2023-11-28T15:31:43.672745] test micro f1b: 0.90686,\tmacro 0.90768\n"
     ]
    }
   ],
   "source": [
    "# eval on test\n",
    "clf_criterion = torch.nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "print(f\"[{datetime.datetime.now().isoformat()}] starting evaluation on test set\")\n",
    "model.eval()\n",
    "epoch_test_loss = []\n",
    "test_epoch_targets = []\n",
    "test_epoch_predictions = []\n",
    "with torch.no_grad():\n",
    "    test_iterator = iter(test_dataloader)\n",
    "    for batch_idx, minibatch in enumerate(pbar := tqdm.tqdm(test_iterator, total=len(test_iterator))):\n",
    "        # format data and move to gpu\n",
    "        x, y, seq_lens, mask_indices, targets = minibatch\n",
    "        x = x.to(device_string)\n",
    "        y = y.to(device_string)\n",
    "        targets = targets.to(device_string)\n",
    "        pad_mask = get_mask_from_lengths(seq_lens, config.max_length, x.device)\n",
    "        clf_logits, mlm_logits = model.forward(x, pad_mask)\n",
    "        clf_loss = clf_criterion(clf_logits, targets)\n",
    "        epoch_test_loss.append(clf_loss.item())\n",
    "        test_epoch_targets += targets.detach().cpu().numpy().tolist()\n",
    "        test_epoch_predictions += clf_logits.max(1).indices.detach().cpu().numpy().tolist()\n",
    "    time.sleep(0.1)\n",
    "    print(f\"[{datetime.datetime.now().isoformat()}] test clf loss : {np.mean(epoch_test_loss):.5f}\")\n",
    "    test_results = evaluate_model(set_name=\"test\", targets=test_epoch_targets, predictions=test_epoch_predictions)\n",
    "    time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = checkpoint[\"output_mapping\"]\n",
    "fullnames = checkpoint[\"extended_labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_codes = [mapping[p] for p in test_epoch_targets]\n",
    "pred_codes = [mapping[p] for p in test_epoch_predictions]\n",
    "true_names = [fullnames[p] for p in true_codes]\n",
    "pred_names = [fullnames[p] for p in pred_codes]\n",
    "true_texts = raw_data.x_test\n",
    "if true_codes != raw_data.y_test:\n",
    "    raise ValueError(f\"raw data test labels do not match true codes, is your checkpoint mapping correct?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data = {\n",
    "    \"true_label\": true_codes,\n",
    "    \"true_name\": true_names,\n",
    "    \"pred_label\": pred_codes,\n",
    "    \"pred_name\": pred_names,\n",
    "    \"text\": true_texts\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(df_data, orient='index').transpose()\n",
    "ord = [\"true_label\", \"true_name\", \"pred_label\", \"pred_name\", \"text\"]\n",
    "df = df[ord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>true_label</th>\n",
       "      <th>true_name</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_name</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mwl</td>\n",
       "      <td>Mirandese</td>\n",
       "      <td>mwl</td>\n",
       "      <td>Mirandese</td>\n",
       "      <td>Ne l fin de l seclo XIX l Japon era inda çconh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nld</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>nld</td>\n",
       "      <td>Dutch</td>\n",
       "      <td>Schiedam is gelegen tussen Rotterdam en Vlaard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ava</td>\n",
       "      <td>Avar</td>\n",
       "      <td>ava</td>\n",
       "      <td>Avar</td>\n",
       "      <td>ГIурусаз батальонал, гьоркьор гIарадабиги лъун...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tcy</td>\n",
       "      <td>Tulu</td>\n",
       "      <td>kan</td>\n",
       "      <td>Kannada</td>\n",
       "      <td>ರಾಜ್ಯಶಾಸ್ತ್ರದ ಪಿತಾಮಹೆ ಅರಿಸ್ಟಾಟಲ್. ರಾಜ್ಯಶಾಸ್ತ್ರ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bjn</td>\n",
       "      <td>Banjar</td>\n",
       "      <td>bjn</td>\n",
       "      <td>Banjar</td>\n",
       "      <td>Halukum adalah kelenjar tiroid nang menonjol d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117495</th>\n",
       "      <td>swa</td>\n",
       "      <td>Swahili (macrolanguage)</td>\n",
       "      <td>swa</td>\n",
       "      <td>Swahili (macrolanguage)</td>\n",
       "      <td>Wakati wa mimba,homa ya Q ni vigumu kutibu kwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117496</th>\n",
       "      <td>glk</td>\n",
       "      <td>Gilaki</td>\n",
       "      <td>fas</td>\n",
       "      <td>Persian</td>\n",
       "      <td>گیلون یک ته تاریخی منطقه‌ سفیدرود دلتای طرف ای...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117497</th>\n",
       "      <td>khm</td>\n",
       "      <td>Central Khmer</td>\n",
       "      <td>khm</td>\n",
       "      <td>Central Khmer</td>\n",
       "      <td>តាម​រយៈ​ការ​ចិញ្ចឹម​មនោសញ្ចេតនា​ជាតិនិយម​បែប​ន...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117498</th>\n",
       "      <td>pnb</td>\n",
       "      <td>Western Panjabi</td>\n",
       "      <td>pnb</td>\n",
       "      <td>Western Panjabi</td>\n",
       "      <td>روس اک وفاق اے تے 1 مارچ 2008ء توں اسدیاں 83 و...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117499</th>\n",
       "      <td>nrm</td>\n",
       "      <td>Narom</td>\n",
       "      <td>fra</td>\n",
       "      <td>French</td>\n",
       "      <td>Chute annaée-lo, la Normaundie n'est pus recou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>117500 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       true_label                true_name pred_label  \\\n",
       "0             mwl                Mirandese        mwl   \n",
       "1             nld                    Dutch        nld   \n",
       "2             ava                     Avar        ava   \n",
       "3             tcy                     Tulu        kan   \n",
       "4             bjn                   Banjar        bjn   \n",
       "...           ...                      ...        ...   \n",
       "117495        swa  Swahili (macrolanguage)        swa   \n",
       "117496        glk                   Gilaki        fas   \n",
       "117497        khm            Central Khmer        khm   \n",
       "117498        pnb          Western Panjabi        pnb   \n",
       "117499        nrm                    Narom        fra   \n",
       "\n",
       "                      pred_name  \\\n",
       "0                     Mirandese   \n",
       "1                         Dutch   \n",
       "2                          Avar   \n",
       "3                       Kannada   \n",
       "4                        Banjar   \n",
       "...                         ...   \n",
       "117495  Swahili (macrolanguage)   \n",
       "117496                  Persian   \n",
       "117497            Central Khmer   \n",
       "117498          Western Panjabi   \n",
       "117499                   French   \n",
       "\n",
       "                                                     text  \n",
       "0       Ne l fin de l seclo XIX l Japon era inda çconh...  \n",
       "1       Schiedam is gelegen tussen Rotterdam en Vlaard...  \n",
       "2       ГIурусаз батальонал, гьоркьор гIарадабиги лъун...  \n",
       "3       ರಾಜ್ಯಶಾಸ್ತ್ರದ ಪಿತಾಮಹೆ ಅರಿಸ್ಟಾಟಲ್. ರಾಜ್ಯಶಾಸ್ತ್ರ...  \n",
       "4       Halukum adalah kelenjar tiroid nang menonjol d...  \n",
       "...                                                   ...  \n",
       "117495  Wakati wa mimba,homa ya Q ni vigumu kutibu kwa...  \n",
       "117496  گیلون یک ته تاریخی منطقه‌ سفیدرود دلتای طرف ای...  \n",
       "117497  តាម​រយៈ​ការ​ចិញ្ចឹម​មនោសញ្ចេតនា​ជាតិនិយម​បែប​ន...  \n",
       "117498  روس اک وفاق اے تے 1 مارچ 2008ء توں اسدیاں 83 و...  \n",
       "117499  Chute annaée-lo, la Normaundie n'est pus recou...  \n",
       "\n",
       "[117500 rows x 5 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hotfix: edit existing checkpoints to include num_classes and label mapping\n",
    "# import glob, os\n",
    "# checkpoint_paths = glob.glob(os.path.join(\"./experiments/wili2018\", \"*.pt\"))\n",
    "# for fpath in checkpoint_paths:\n",
    "#     checkpoint = torch.load(checkpoint_filepath)\n",
    "#     checkpoint[\"num_classes\"] = num_classes\n",
    "#     torch.save(checkpoint, fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
