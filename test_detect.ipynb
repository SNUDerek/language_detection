{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from loguru import logger\n",
    "\n",
    "from language_detection.data import transform_text, get_mask_from_lengths\n",
    "from language_detection.model import TrainingConfig, TransformerClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTEBOOK ONLY\n",
    "from dataclasses import dataclass\n",
    "@dataclass\n",
    "class Args:\n",
    "    checkpoint_file: str = \"experiments/wili2018/wili2018-checkpoint-000020.pt\"\n",
    "    debug: bool = False\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageDetector:\n",
    "\n",
    "    def __init__(self, checkpoint_filepath: str):\n",
    "        logger.info(\"initializing detector from checkpoint '{checkpoint_filepath}'...\")\n",
    "        self.checkpoint = self.load_checkpoint(checkpoint_filepath)\n",
    "        if \"output_mapping\" not in self.checkpoint:\n",
    "            raise ValueError(\"checkpoint file is missing 'output_mapping'!\")\n",
    "        self.config = self.load_config()\n",
    "        self.model = self.load_model()\n",
    "        self.device = str(list(self.model.parameters())[0].device)\n",
    "        random.seed(self.config.seed)\n",
    "        np.random.seed(self.config.seed)\n",
    "        torch.manual_seed(self.config.seed)\n",
    "        logger.info(f\"done! (using device '{self.device}')\")\n",
    "\n",
    "    def load_checkpoint(self, checkpoint_path: str):\n",
    "        if not pathlib.Path(checkpoint_path).is_file():\n",
    "            raise ValueError(f\"checkpoint file '{checkpoint_path}' does not exist!\")\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "        return checkpoint\n",
    "    \n",
    "    def load_config(self) -> TrainingConfig:\n",
    "        if not self.checkpoint:\n",
    "            raise RuntimeError(\"no checkpoint loaded, load checkpoint first!\")\n",
    "        config = TrainingConfig(**self.checkpoint[\"config\"])\n",
    "        return config\n",
    "\n",
    "    def load_model(self) -> TransformerClassifier:\n",
    "        if not self.config:\n",
    "            raise RuntimeError(\"no config loaded, load config first!\")\n",
    "        model = TransformerClassifier(num_classes=self.checkpoint[\"num_classes\"])\n",
    "        model.load_state_dict(self.checkpoint[\"model_state_dict\"])\n",
    "        if torch.cuda.is_available():\n",
    "            device_string = \"cuda\"\n",
    "        else:\n",
    "            device_string = \"cpu\"\n",
    "        _ = model.to(device_string)\n",
    "        model.eval()\n",
    "        return model\n",
    "\n",
    "    def create_input_tensor(self, test_text: str) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        \"\"\"create model inputs for single sample\"\"\"\n",
    "        x_input, y_output, seq_len, _idxs = transform_text(\n",
    "            text=test_text, \n",
    "            is_training=False, \n",
    "            max_length=self.config.max_length\n",
    "        )\n",
    "        x_input = x_input.reshape(1, self.config.max_length)\n",
    "        seq_lens = torch.tensor([seq_len])\n",
    "        x_input = x_input.to(self.device)\n",
    "        pad_mask = get_mask_from_lengths(seq_lens, self.config.max_length, self.device)\n",
    "        return x_input, pad_mask\n",
    "    \n",
    "    def predict(self, test_text: str) -> str:\n",
    "        x_input, x_mask = self.create_input_tensor(test_text)\n",
    "        clf_logits, _mlm_logits = self.model.forward(x_input, x_mask)\n",
    "        preds = clf_logits.max(1).indices.detach().cpu().numpy()\n",
    "        lang_code = self.checkpoint[\"output_mapping\"][preds[0]]\n",
    "        if \"extended_labels\" in self.checkpoint:\n",
    "            lang_name = self.checkpoint[\"extended_labels\"][lang_code]\n",
    "            return lang_name\n",
    "        return lang_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_detector = LanguageDetector(args.checkpoint_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"Sportief succes kost veel geld in de Formule 1. Red Bull, het team van wereldkampioen Max Verstappen, moet volgend jaar meer dan ooit betalen om te mogen deelnemen aan de koningsklasse\"\n",
    "print(lang_detector.predict(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"Außenministerin Baerbock formuliert drei deutsche Ziele für die COP28: Mehr Tempo, mehr Solidarität, mehr Partnerschaft.\"\n",
    "print(lang_detector.predict(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"제가 이 채널에서는 어디에 썼는지 지금 당장 찾지를 못했는데, PR 만들 때 format에도 써놨습니다. 예를 들면 PR만들려고 열어 보시면 자동으로 이런 문구가 떠요(사람들이 안 볼까봐 제가 일부러 넣어뒀습니다\"\n",
    "print(lang_detector.predict(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"日本語のニュースや番組をテレビとラジオで海外向けに放送しています。海外にお住まいの方、旅行中の方にも情報をお届けします。\"\n",
    "print(lang_detector.predict(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = \"ي بي سي العربية هي شبكة لنقل الأخبار والمعلومات ومقاطع الفيديو إلى العالم عبر عدة وسائط، تشمل الإنترنت ومواقع التواصل الاجتماعي والراديو والتلفزيون ...\"\n",
    "print(lang_detector.predict(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
